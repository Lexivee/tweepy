timeline <- fromJSON(file="~/allLeeds.json" )
fromJSON(file="~/allLeeds.json" )
library(rjson)
fromJSON(file="~/allLeeds.json" )
timeline
timeline <- fromJSON(file="~/allLeeds.json" )
timeline
timeline[[1]]
timeline[[2]]
?fromJSON
library(rjsonio)
install.packages("rjsonio")
install.packages("RJSONIO")
library(rjsonlite)
install.packages("jsonlite")
library(rjsonlite)
library(jsonlite)
timeline <- fromJSON(file="~/allLeeds.json" )
timeline <- fromJSON("~/allLeeds.json")
timeline
timeline <- fromJSON("~/allLeeds.json", simplifyDataFrame=T)
timeline
timeline <- fromJSON(json_str="~/allLeeds.json")
?fromJSON
timeline <- fromJSON("allLeeds2NB.json") #
timeline
timeline <- fromJSON("allLeeds2NB.json")
timeline
timeline <- fromJSON("allLeeds2NBRs.json")
timeline <- fromJSON("~/allLeeds.json") # same issue: is it due to blank lines?
timeline
timeline <- fromJSON("allLeeds.json") # same issue: is it due to blank lines?
timeline <- fromJSON("allLeeds2.json") # same issue: is it due to blank lines?
timeline
timeline <- fromJSON("allLeeds2.json") # same issue: is it due to blank lines?
timeline
library(rjson)
tweet <- fromJSON("data/471045631050801152")
timeline <- fromJSON(file="~/allLeeds.json" )
timeline[[2]]
timeline$retweeted
timelist=unlist(timeline)
tweets=timelist[names(timelist)=="text"]
names=timelist[names(timelist)=="user.screen_name"]
times=timelist[names(timelist)=="created_at"]
tweet.frame=data.frame(tweets,names,times) # only loaded 1 tweet!
tweet.frame
tweet <- fromJSON("data/471045631050801152")
tweet <- fromJSON(file="data/471045631050801152")
tweet
str(tweet)
tweet$created_at
tweet$coordinates
tweet <- fromJSON(file="data/tweets.json")
str(tweet)
tweet <- fromJSON(file="data/tweets.json")
str(tweet)
tweet$coordinates
tweet
sprintf("[%s]", paste(readLines("data/tweets.json"),collapse=","))
tweets <- sprintf("[%s]", paste(readLines("data/tweets.json"),collapse=","))
body <- sapply(tweets, "[[", "body")
tweets[[1]]
tweets[[2]]
tweets <- sprintf("[%s]", paste(readLines("data/tweets.json"),collapse=","))
tweets
tweets <- sprintf("[%s]", paste(readLines("data/tweets.json"),collapse=","))
tweets
body <- sapply(tweets, "[[")
library(rjson)
library(RCurl)
library(rjson)
library(RCurl)
library(plyr)
tweets <- sprintf("[%s]", paste(readLines("data/tweets.json"),collapse=","))
tweets
tweets <- fromJSON(sprintf("[%s]", paste(readLines("data/tweets.json"),collapse=",")))
tweets
tweets[[2]]
body <- sapply(tweets, "[[")
body <- sapply(tweets, "[[", "body")
body
body <- sapply(tweets, "[[", "coordinates")
body
unlist(body)
l <- fromJSON('[{"winner":"68694999",  "votes":[
{"ts":"Thu Mar 25 03:13:01 UTC 2010", "user":{"name":"Lamur","user_id":"68694999"}},
{"ts":"Thu Mar 25 03:13:08 UTC 2010", "user":{"name":"Lamur","user_id":"68694999"}}],
"lastVote":{"timestamp":1269486788526,"user":
{"name":"Lamur","user_id":"68694999"}},"startPrice":0}]'
)
m <- lapply(
l[[1]]$votes,
function(x) c(x$user['name'], x$user['user_id'], x['ts'])
)
m <- do.call(rbind, m)
m
l[[1]]$winner
l
m <- lapply(
tweets[[1]]$coordinates$coordinates,
function(x) c(x$coordinates[1], x$coordinates[2])
)
m <- lapply(
tweets[[1]]$coordinates,
function(x) c(x$coordinates[1], x$coordinates[2])
)
tweets[[1]]$coordinates
tweets[[1]]$coordinates$coordinates,
tweets[[1]]$coordinates$coordinates
tweets <- fromJSON(sprintf("[%s]", paste(readLines("data/tweets.json"),collapse=",")))
tweets[[1]]$coordinates$coordinates
m <- lapply(
tweets[[1]]$coordinates$coordinates,
function(x) c(x)
)
m
do.call(m, rbind)
help.search(list)
help.search("list")
help.search("list", package="dplyr")
library(plyr)
ldply(tweets)
ldply(tweets, data.frame)
tweets[[1]]$coordinates$coordinates
tweets[[1]]$coordinates$coordinates # the coordinates
unlist(tweets)
tweets[[2]]
head(tweets[[2]])
length(tweets[[2]])
matrix(unlist(tweets), ncol=23)
matrix(unlist(tweets), ncol=23, byrow=T)
matrix(unlist(tweets), ncol=23, byrow=F)
ts <- fromJSON(sprintf("[%s]", paste(readLines("data/tweets.json"),collapse=",")))
length(ts[[2]])
ts[[1]]$coordinates$coordinates # the coordinates
sapply(ts, function(x), x$coordinates$coordinates )
sapply(ts, function(x) x$coordinates$coordinates )
unlist(sapply(ts, function(x) x$coordinates$coordinates ))
sapply(ts, function(x) x$coordinates$coordinates )
matrix(unlist(sapply(ts, function(x) x$coordinates$coordinates )), ncol=2)
matrix(unlist(sapply(ts, function(x) x$coordinates$coordinates )), ncol=2, byrow=T)
text <- sapply(ts, function(x) x$text )
text
text <- unlist(ts)
text
text <- unlist(text)
text
text <- sapply(ts, function(x) x$text )
text <- unlist(text)
text
tdf <- data.frame(text = text)
tdf <- cbind(tdf, coords)
coords <- matrix(unlist(sapply(ts, function(x) x$coordinates$coordinates )), ncol=2, byrow=T)
tdf <- cbind(tdf, coords)
coords
tdf
text <- sapply(ts, function(x) x$text )
text <- unlist(text)
text
tdf <- data.frame(text = text)
tdf <- cbind(tdf, coords)
text <- unlist(text)[-1]
text <- sapply(ts, function(x) x$text )
text <- unlist(text)[-1]
text
tdf <- data.frame(text = text)
tdf <- cbind(tdf, coords)
tdf
plot(tdf$1, tdf$2)
plot(tdf$1, tdf$2)
coords <- as.data.frame(coords)
coords
plot(tdf$V1, tdf$V2)
ts <- fromJSON(sprintf("[%s]", paste(readLines("data/tweets.json"),collapse=",")))
length(ts[[2]])
ts[[1]]$coordinates$coordinates # the coordinates
sapply(ts, function(x) x$coordinates$coordinates )
coords <- matrix(unlist(sapply(ts, function(x) x$coordinates$coordinates )), ncol=2, byrow=T)
coords <- as.data.frame(coords)
text <- sapply(ts, function(x) x$text )
text <- unlist(text)[-1]
text
tdf <- data.frame(text = text) # create R data.frame
tdf <- cbind(tdf, coords)
tdf
plot(tdf$V1, tdf$V2)
text(tdf$V1, tdf$V2, labels=tdf$text)
??SpatialPolygonsDataFrame
library(rjson)
tweet <- fromJSON # loads 1st tweet, but no more
tweet
tweet <- fromJSON("data/tweets.json") # loads 1st tweet, but no more
tweet
tweet <- fromJSON("data/tweets.json") # loads 1st tweet, but no more
tweet
tweet <- fromJSON("data/tweets.json") # loads 1st tweet, but no more
tweet <- fromJSON(file = "data/tweets.json") # loads 1st tweet, but no more
tweet
names(tweet)
tweet$text
ts <- fromJSON(sprintf("[%s]", paste(readLines("data/tweets.json"),collapse=",")))
length(ts[[2]])
ts[[1]]$coordinates$coordinates # the coordinates
ts <- fromJSON(sprintf("[%s]", paste(readLines("data/tweets.json"),collapse=",")))
ts[[2]]$text
ts[[1]]$coordinates$coordinates # the coordinates
sapply(ts, function(x) x$coordinates$coordinates )
sapply(ts, function(x) x$coordinates$coordinates )[[1:3]]
sapply(ts, function(x) x$coordinates$coordinates )[[1]]
coords <- matrix(unlist(sapply(ts, function(x) x$coordinates$coordinates )), ncol=2, byrow=T)
coords
coords <- as.data.frame(coords)
coords
text <- sapply(ts, function(x) x$text )
text <- unlist(text)[-1]
text
tdf <- data.frame(text = text) # create R data.frame
tdf <- cbind(tdf, coords)
tdf
text <- sapply(ts, function(x) x$text )
text <- unlist(text)[-1]
text[1:3]
tdf <- data.frame(text = text) # create R data.frame
tdf <- cbind(tdf, coords)
tdf
load("../tweet_store/.RData")
ls()
nrow(gT)
nrow(geoT)
nrow(geoT) / 1000000
range(geoT$Time)
summary(nchar(geoT$Text))
geoT[ which.max(nchar(geoT$Text)), ]
library(ggmap)
install.packages("ggmap")
library(ggmap)
ggmap(get_map(bbox(geoT)))
ggmap(get_map(bbox(geoT))) + geom_point(data = geoT@data, aes(x = Lon, y = Lat), alpha = 0.2)
geoT@data[sample(1:nrow(geoT), size = nrow(geoT) / 1000), ]
ggmap(get_map(bbox(geoT))) + geom_point(data = geoT@data[sample(1:nrow(geoT), size = nrow(geoT) / 1000), ],
aes(x = Lon, y = Lat), alpha = 0.2)
names(geoT)
nrow(grep("robber", geoT$Text, ignore.case = T))
length(grep("robber", geoT$Text, ignore.case = T))
length(grep("stole|steal", geoT$Text, ignore.case = T))
head(geoT$Text[grep("robber", geoT$Text, ignore.case = T)])
length(grep("break-in|breakin", geoT$Text, ignore.case = T))
head(geoT$Text[grep("break-in|breakin", geoT$Text, ignore.case = T)])
head(geoT$Text[grep("break-in", geoT$Text, ignore.case = T)])
length(grep("break-in", geoT$Text, ignore.case = T))
length(grep("shoplift|shop-lift", geoT$Text, ignore.case = T))
head(geoT$Text[grep("shoplift|shop-lift", geoT$Text, ignore.case = T)])
length(grep("thei", geoT$Text, ignore.case = T))
head(geoT$Text[grep("thei", geoT$Text, ignore.case = T)])
length(grep("burgl", geoT$Text, ignore.case = T))
head(geoT$Text[grep("burgl", geoT$Text, ignore.case = T)])
head(geoT$Text[grep("thei(fv)", geoT$Text, ignore.case = T)])
head(geoT$Text[grep("thei(f|v)", geoT$Text, ignore.case = T)])
length(grep("robber", geoT$Text, ignore.case = T))
head(geoT$Text[grep("robber", geoT$Text, ignore.case = T)])
length(grep("burgl", geoT$Text, ignore.case = T))
head(geoT$Text[grep("burgl", geoT$Text, ignore.case = T)])
length(grep("stole|steal", geoT$Text, ignore.case = T))
head(geoT$Text[grep("stole|steal", geoT$Text, ignore.case = T)])
length(grep("shoplift|shop-lift", geoT$Text, ignore.case = T))
head(geoT$Text[grep("shoplift|shop-lift", geoT$Text, ignore.case = T)])
length(grep("thei", geoT$Text, ignore.case = T))
head(geoT$Text[grep("thei(f|v)", geoT$Text, ignore.case = T)])
length(grep("thei(f|v)", geoT$Text, ignore.case = T))
selection <- grep("robber|burgl|stole|steal|shoplift|shop-lift|thei(f|v)", geoT$Text, ignore.case = T)
crimeTweets <- geoT[selection,]
nrow(crimeTweets)
library(maptools)
x <- spRbind(crimeTweets, geoT[sample(1:nrow(geoT), size = nrow(crimeTweets)), ])
ggplot(data = x@data, aes(x = Lon, y = Lat)) + geom_point(alpha = 0.1)
x <- geoT[sample(1:nrow(geoT), size = nrow(crimeTweets)), ]
crimeTweets$type <- "Crime"
set.seed(2014) # reproducible starting point for random numbers
crimeTweets$type <- "Crime"
x <- geoT[sample(1:nrow(geoT), size = nrow(crimeTweets)), ]
x$type <- "Baseline"
x <- spRbind(crimeTweets, x)
ggplot(data = x@data, aes(x = Lon, y = Lat)) + geom_point(alpha = 0.1) +
facet_grid(~ type)
ggplot(data = x@data, aes(x = Lon, y = Lat)) + geom_point(alpha = 0.1) +
geom_density2d(fill = ..density..)
ggplot(data = x@data, aes(x = Lon, y = Lat)) + geom_point(alpha = 0.1) +
geom_density2d(aes(fill = ..density..))
ggplot(data = x@data, aes(x = Lon, y = Lat)) + geom_point(alpha = 0.1) +
geom_density2d(aes(fill = ..level..))
ggplot(data = x@data, aes(x = Lon, y = Lat)) + geom_point(alpha = 0.1) +
geom_density2d(aes(fill = ..level..), geom = "polygon")
ggplot(data = x@data, aes(x = Lon, y = Lat)) + geom_point(alpha = 0.1) +
stat_density2d(aes(fill = ..level..), geom = "polygon")
ggplot(data = x@data, aes(x = Lon, y = Lat)) + geom_point(alpha = 0.1) +
stat_density2d(aes(fill = ..level.., alpha=..level..), geom = "polygon") +
facet_grid(~ type)
ggplot(data = x@data, aes(x = Lon, y = Lat)) + geom_point(alpha = 0.1) +
stat_density2d(aes(fill = ..level.., alpha=..level..), geom = "polygon") +
facet_grid(~ type) + scale_fill_continuous(low = "green", high = "red")
ggplot(data = x@data, aes(x = Lon, y = Lat)) + geom_point(alpha = 0.1) +
stat_density2d(aes(fill = ..level..), alpha = 0.3, geom = "polygon") +
facet_grid(~ type) + scale_fill_continuous(low = "green", high = "red")
write.csv(geoT@data, "~/Dropbox/Public/crimeTweets.csv")
write.csv(crimeTweets@data, "~/Dropbox/Public/crimeTweets.csv")
length(grep("pennine way", geoT$Text, ignore.case = T))
head(geoT$Text[grep("pennine way", geoT$Text, ignore.case = T)])
length(grep("pennine", geoT$Text, ignore.case = T))
head(geoT$Text[grep("pennine", geoT$Text, ignore.case = T)])
download.file(url = "http://hiking.waymarkedtrails.org/en/routebrowser/63872/gpx")
download.file(url = "http://hiking.waymarkedtrails.org/en/routebrowser/63872/gpx", "pennine.gpx")
source('~/.active-rstudio-document', echo=TRUE)
download.file(url = "http://hiking.waymarkedtrails.org/en/routebrowser/63872/gpx", "pennine.gpx")
library(rgdal)
ogrListLayers("pennine.gpx")
pw <- readOGR("pennine.gpx", layer = "routes")
pw <- readOGR("pennine.gpx", layer = "tracks")
library(rgeos)
gBuffer(pw, width = 0.3)
pwBuf <- gBuffer(pw, width = 0.3)
plot(pwBuf)
pw <- spTransform(pw, CRS("+init=epsg:27700"))
library(rgeos)
pwBuf <- gBuffer(pw, width = 2000)
plot(pwBuf)
pwBuf <- gBuffer(pw, width = 5000)
pwBuf <- spTransform(pwBuf, CRS("+init=epsg:4326"))
geoT[pwBuf, ]
pwBuf <- spTransform(pwBuf, CRS(proj4string(geoT)))
pwBuf <- spTransform(pwBuf, CRS("+init=epsg:4326"))
proj4string(geoT) <- CRS("+init=epsg:4326")
geoT[pwBuf, ]
pwBuf <- gBuffer(pw, width = 20000) # create 5 km buffer
plot(pwBuf) # plot to test dimensions make sense
pwBuf <- spTransform(pwBuf, CRS("+init=epsg:4326"))
proj4string(geoT) <- CRS("+init=epsg:4326")
geoT[pwBuf, ]
pwBuf <- gBuffer(pw, width = 10000) # create 10 km buffer
plot(pwBuf) # plot to test dimensions make sense
pwBuf <- spTransform(pwBuf, CRS("+init=epsg:4326"))
proj4string(geoT) <- CRS("+init=epsg:4326")
PennineTweets <- geoT[pwBuf, ]
nrow(PennineTweets)
pwBuf <- gBuffer(pw, width = 15000) # create 10 km buffer
plot(pwBuf) # plot to test dimensions make sense
pwBuf <- spTransform(pwBuf, CRS("+init=epsg:4326"))
proj4string(geoT) <- CRS("+init=epsg:4326")
PennineTweets <- geoT[pwBuf, ]
nrow(PennineTweets)
points(PennineTweets)
plot(pwBuf)
points(PennineTweets)
pTweets <- geoT[ grep("pennine", geoT$Text, ignore.case = T) , ]
write.csv(pTweets, "~/Dropbox/Public/tmp/ptweets.csv")
load("../tweet_store/.RData")
install.packages("RSQLite")
ggplot(data = x@data, aes(x = Lon, y = Lat)) + geom_point(alpha = 0.1) +
stat_density2d(aes(fill = ..level..), alpha = 0.3, geom = "polygon") +
facet_grid(~ type) + scale_fill_continuous(low = "green", high = "red")
set.seed(2014) # reproducible starting point for random numbers
crimeTweets$type <- "Crime"
x <- geoT[sample(1:nrow(geoT), size = nrow(crimeTweets)), ]
x$type <- "Baseline"
selection <- grep("robber|burgl|stole|steal|shoplift|shop-lift|thei(f|v)", geoT$Text, ignore.case = T)
crimeTweets <- geoT[selection,]
nrow(crimeTweets)
library(maptools) # load package
set.seed(2014) # reproducible starting point for random numbers
crimeTweets$type <- "Crime"
x <- geoT[sample(1:nrow(geoT), size = nrow(crimeTweets)), ]
x$type <- "Baseline"
x <- spRbind(crimeTweets, x)
ggplot(data = x@data, aes(x = Lon, y = Lat)) + geom_point(alpha = 0.1) +
stat_density2d(aes(fill = ..level..), alpha = 0.3, geom = "polygon") +
facet_grid(~ type) + scale_fill_continuous(low = "green", high = "red")
library(tm)
?tm
vc <- tm::as.VCorpus(crimeTweets$Text)
vc <- VectorSource(crimeTweets$Text)
vc <- VCorpus(VectorSource(crimeTweets$Text))
vc <- tm_map(vc, content_transformer(tolower))
dtm <- DocumentTermMatrix(vc)
findFreqTerms(dtm, 20)
findFreqTerms(dtm, 50)
findFreqTerms(dtm, 100)
findFreqTerms(dtm, 100)[ nchar(findFreqTerms(dtm, 100)) > 5]
findFreqTerms(dtm, 50)[ nchar(findFreqTerms(dtm, 50)) > 5]
findAssocs(x = vc, terms = "steal", corlimit = 0.5)
findAssocs(x = dtm, terms = "steal", corlimit = 0.5)
findAssocs(x = dtm, terms = "steal", corlimit = 0.3)
findAssocs(x = dtm, terms = "steal", corlimit = 0.2)
findAssocs(x = dtm, terms = "steal", corlimit = 0.1)
findAssocs(x = dtm, terms = "burgl", corlimit = 0.1)
findAssocs(x = dtm, terms = "burgle", corlimit = 0.1)
findAssocs(x = dtm, terms = "burgl*", corlimit = 0.1)
findAssocs(x = dtm, terms = "burglary", corlimit = 0.1)
head(findAssocs(x = dtm, terms = "theif", corlimit = 0.1))
head(findAssocs(x = dtm, terms = "robbery", corlimit = 0.1))
head(findAssocs(x = dtm, terms = "steal", corlimit = 0.1))
head(findAssocs(x = dtm, terms = "burgle", corlimit = 0.1))
head(findAssocs(x = dtm, terms = "burglary", corlimit = 0.1))
head(findAssocs(x = dtm, terms = "shoplift", corlimit = 0.1))
head(findAssocs(x = dtm, terms = "theif", corlimit = 0.1))
head(findAssocs(x = dtm, terms = "police", corlimit = 0.1))
?stopwords
stopwords()
vc <- tm_map(vc, removeWords, stopwords(kind = "en")) # remove 'stopwords' we're not interested in
dtm <- DocumentTermMatrix(vc)
findFreqTerms(dtm, 50)[ nchar(findFreqTerms(dtm, 50)) > 5] # words more than 5 letters long appearing 50+ times
findFreqTerms(dtm, 30)[ nchar(findFreqTerms(dtm, 30)) > 5] # words more than 5 letters long appearing 50+ times
head(findAssocs(x = dtm, terms = "robbery", corlimit = 0.1))
head(findAssocs(x = dtm, terms = "steal", corlimit = 0.1))
head(findAssocs(x = dtm, terms = "burgle", corlimit = 0.1))
